<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Limitations of K-Means | Tech Nexus | Knighthood Mindset</title>
  <link rel="stylesheet" href="exp.css" />
</head>
<body>
  <div class="top-banner">
    <h1>Tech Nexus</h1>
    <h2>Your Study Companion</h2>
  </div>

  <main>
    <section>
        <h3>Limitations of K-Means</h3>
        <p><strong>1. Sensitive to Outliers:</strong>K-means clustering can be heavily influenced by outliers, which are data points that are significantly different from the rest of the data. Outliers can affect the calculation of centroids, leading to poor clustering results</p>
        <p><strong>2. Assumes Spherical Clusters:</strong>K-means assumes that clusters are spherical in shape, which may not always be the case in real-world data. If clusters have irregular shapes or varying densities, K-means may not be able to capture them effectively</p>
        <p><strong>3. Initialization Matters:</strong>The initial selection of centroids can significantly impact the clustering results. Different initializations may lead to different solutions, and some initializations may result in poor clustering performance</p>
        <p><strong>4. Fixed Number of Clusters:</strong>K-means requires the number of clusters (K) to be specified in advance. However, determining the optimal number of clusters can be challenging, especially for complex datasets</p>
        <p><strong>5. Not Suitable for Complex Data:</strong>K-means may not perform well with complex or high-dimensional data, such as images or text data. These types of data often require more sophisticated clustering algorithms or techniques</p>
        <p><strong>6. Sensitive to Scale:</strong>K-means can be sensitive to the scale of the data. Features with large ranges may dominate the clustering results, while features with small ranges may have little impact</p>
        <p><strong>7. Not Robust to Noise:</strong>K-means can be affected by noisy data, which can lead to poor clustering results. Noise can be caused by errors in data collection, measurement, or processing</p>
        <p><strong>8. Not Suitable for Clusters with Varying Densities:</strong>K-means assumes that clusters have similar densities. However, in real-world data, clusters can have varying densities, which can make it challenging for K-means to identify them effectively</p>
        <p><strong>9. Computational Complexity:</strong>K-means can be computationally expensive, especially for large datasets. The algorithm's complexity can increase with the number of data points, features, and clusters</p>
        <p>These limitations highlight the importance of carefully evaluating the suitability of K-means clustering for a particular problem and considering alternative clustering algorithms or techniques as needed</p>
    </section>
    
  </main>

  <footer>
    <a href="ML_unit4.html" class="back-btn">‚Üê Back to Unit 5 Topics</a>
  </footer>
  
</body>
</html>
  
