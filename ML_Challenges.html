<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Challenges of Machine Learning | Tech Nexus | Knighthood Mindest</title>
  <link rel="stylesheet" href="exp.css" />
</head>
<body>
  <div class="top-banner">
    <h1>Tech Nexus</h1>
    <h2>Your Study Companion</h2>
  </div>

  <main>
  <section>
    <h3>Challenges of Machine Learning</h3>
  </section>
  <section>
    <h5>Data Quality Issus</h5>
    <p><strong>1. Noise and outliers:</strong>Noisy or outlier data can affect model performance.</p>
    <p><strong>2. Missing values:</strong>Handling missing data can be challenging.</p>
    <p><strong>3. Data imbalance:</strong>Imbalanced datasets can lead to biased models.</p>
    <h5>Overfitting/Underfitting</h5>
    <p><strong>1. Overfitting:</strong>Models that are too complex may memorize the training data, failing to generalize to new data.</p>
    <p><strong>2. Underfitting:</strong>Models that are too simple may not capture the underlying patterns in the data.</p>
    <h5>3Interpretability</h5>
    <p><strong>Black box models:</strong>Some models, like deep neural networks, can be difficult to interpret.</p>
    <p><strong>Feature importance:</strong>Understanding which features contribute to model predictions.</p>
    <h5>Scalability</h5>
    <p><strong>Large datasets:</strong>Handling massive datasets requires efficient algorithms and infrastructure.</p>
    <p><strong>Deployment:</strong>Deploying models in production environments can be challenging.</p>
    <h5>Bias and Fairness</h5>
    <p><strong>Biased data:</strong>Models can inherit biases present in the training data.</p>
    <p><strong>Fairness metrics:</strong>Ensuring models are fair and unbiased requires careful evaluation.</p>
    <h5>Security</h5>
    <p><strong>Adversarial attacks:</strong>Models can be vulnerable to attacks designed to mislead them.</p>
    <p><strong>Data poisoning:</strong>Attackers may attempt to poison the training data.</p>
    <h5>Explainability</h5>
    <p><strong>Model transparency:</strong>Providing insights into model decisions and predictions.</p>
    <p><strong>Model interpretability techniques:</strong>Techniques like feature importance, SHAP values, and LIME can help explain model decisions.</p>
    <h5>Data Drift</h5>
    <p><strong>Concept drift:</strong>Changes in the underlying data distribution over time.</p>
    <p><strong>Model updating:</strong>Regularly updating models to adapt to changing data distributions.</p>
    <h5>Model Selection</h5>
    <p><strong>Choosing the right model:</strong>Selecting the best model for a specific problem.</p>
    <p><strong>Hyperparameter tuning:</strong>Tuning model hyperparameters for optimal performance.</p>
    <h5>Ethics and Responsibility</h5>
    <p><strong>Model accountability:</strong>Ensuring models are accountable and transparent.</p>
    <p><strong>Regulatory compliance:</strong>Complying with regulations like GDPR and CCPA.</p>
    <p>Addressing these challenges requires careful consideration of data quality, model selection, and ongoing monitoring and maintenance.</p>
  </section>
   </main>

    <footer>
    <a href="ML_unit2.html" class="back-btn">‚Üê Back to Unit 2 Topics</a>
    </footer>

 </body>
</html>
